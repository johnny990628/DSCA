{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'HierSurv', 'experiment': 'sim', 'seed_data_split': 0, 'path_data_split': './data_split/tcga_luad_merged/tcga_luad_merged-seed42-fold{}.npz', 'csv_path': '/work/u6658716/TCGA-LUAD/DSCA/data_split/tcga_luad_merged/tcga_luad_merged_path_full.csv', 'h5_dir': '/work/u6658716/TCGA-LUAD/PATCHES/LUAD/tiles-10x-s224', 'slide_dir': '/work/u6658716/TCGA-LUAD/DATASETS/TCGA/LUAD', 'ckpt_path': '/work/u6658716/TCGA-LUAD/CLAM/checkpoints/conch/pytorch_model.bin', 'lora_checkpoint': None, 'target_patch_size': 224, 'dataset_name': 'tcga_luad_merged', 'magnification': '5-10', 'path_patchx20': '/work/u6658716/TCGA-LUAD/PATCHES/LUAD/tiles-5x-s224/tiles-10x-s224/feats-RN50-B-s224/pt_files', 'path_patchx5': '/work/u6658716/TCGA-LUAD/PATCHES/LUAD/tiles-5x-s224/feats-RN50-B-s224/pt_files', 'path_coordx5': '/work/u6658716/TCGA-LUAD/PATCHES/LUAD/tiles-5x-s224/patches', 'path_label': './data_split/tcga_luad_merged/tcga_luad_merged_path_full.csv', 'label_discrete': False, 'bins_discrete': 4, 'feat_format': 'pt', 'num_patch_sampling': -1, 'no_cuda': False, 'cuda_id': 0, 'use_deepspeed': True, 'seed': 42, 'dims': '1024-256-256-1', 'cell_in_dim': 1024, 'top_k': 500, 'isGene': False, 'early_fusion': 'coattn', 'save_path': './results-luad-hier/ple_resnet50_5x10x_224', 'save_prediction': True, 'emb_x5_backbone': 'conv1d', 'emb_x5_ksize': 5, 'emb_x20_backbone': 'capool', 'emb_x20_dw_conv': False, 'emb_x20_ksize': 3, 'tra_position_emb': True, 'tra_backbone': 'Transformer', 'tra_nhead': 1, 'tra_num_layers': 1, 'tra_ksize': 3, 'tra_dw_conv': False, 'tra_epsilon': 0.8, 'join': 'post', 'fusion': 'fusion', 'pool': 'gap', 'dropout': 0.6, 'loss': 'survple', 'alpha': 0.1, 'reg_l1': 1e-05, 'batch_size': 1, 'num_workers': 8, 'epochs': 150, 'bp_every_iters': 338, 'monitor_metrics': 'ci', 'es_patience': 30, 'es_warmup': 0, 'es_start_epoch': 0, 'es_verbose': True, 'opt': 'adam', 'weight_decay': 0.0001, 'lr': 1e-05, 'opt_eps': None, 'opt_betas': None, 'opt_momentum': None}\n",
      "Scale for magnifications [5, 10] is 2\n",
      "[2025-05-01 18:12:12,922] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.15.0, git-hash=260a70f, git-branch=HEAD\n",
      "[2025-05-01 18:12:12,923] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-05-01 18:12:12,923] [INFO] [comm.py:667:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpi4py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     83\u001b[0m     config \u001b[38;5;241m=\u001b[39m get_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/work/u6658716/TCGA-LUAD/DSCA/config/config_ms.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 43\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# === DeepSpeed 初始化 ===\u001b[39;00m\n\u001b[1;32m     42\u001b[0m ds_config_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/work/u6658716/TCGA-LUAD/DSCA/config/ds_config.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 43\u001b[0m model_engine, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdeepspeed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_config_path\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# === 載入 best model（DeepSpeed 格式） ===\u001b[39;00m\n\u001b[1;32m     49\u001b[0m load_path \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/clam/lib/python3.8/site-packages/deepspeed/__init__.py:144\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, distributed_port, mpu, dist_init_required, collate_fn, config, mesh_param, config_params)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comm \u001b[38;5;28;01mas\u001b[39;00m dist\n\u001b[1;32m    143\u001b[0m dist_backend \u001b[38;5;241m=\u001b[39m get_accelerator()\u001b[38;5;241m.\u001b[39mcommunication_backend_name()\n\u001b[0;32m--> 144\u001b[0m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_distributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdistributed_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdist_init_required\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_init_required\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m##TODO: combine reuse mpu as mesh device and vice versa\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Set config using config_params for backwards compat\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m config_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/clam/lib/python3.8/site-packages/deepspeed/comm/comm.py:673\u001b[0m, in \u001b[0;36minit_distributed\u001b[0;34m(dist_backend, auto_mpi_discovery, distributed_port, verbose, timeout, init_method, dist_init_required, config, rank, world_size)\u001b[0m\n\u001b[1;32m    671\u001b[0m         patch_aws_sm_env_for_torch_nccl_backend(verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 673\u001b[0m         \u001b[43mmpi_discovery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistributed_port\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cdb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m cdb\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/clam/lib/python3.8/site-packages/deepspeed/comm/comm.py:692\u001b[0m, in \u001b[0;36mmpi_discovery\u001b[0;34m(distributed_port, verbose)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmpi_discovery\u001b[39m(distributed_port\u001b[38;5;241m=\u001b[39mTORCH_DISTRIBUTED_DEFAULT_PORT, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    Discovery MPI environment via mpi4py and map to relevant dist state\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpi4py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MPI\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     comm \u001b[38;5;241m=\u001b[39m MPI\u001b[38;5;241m.\u001b[39mCOMM_WORLD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpi4py'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from model.HierNet import WSIHierNet\n",
    "from dataset import prepare_dataset\n",
    "from utils import *\n",
    "from types import SimpleNamespace\n",
    "import yaml\n",
    "from eval import evaluator\n",
    "import deepspeed\n",
    "\n",
    "\n",
    "def run_test(cfg):\n",
    "    # === 設定設備與模型 ===\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dims = [int(x) for x in cfg['dims'].split('-')]\n",
    "\n",
    "    print(cfg)\n",
    "    scales = list(map(int, cfg['magnification'].split('-')))\n",
    "    scale = int(scales[1] / scales[0])\n",
    "    print(f\"Scale for magnifications {scales} is {scale}\")\n",
    "\n",
    "    cfg_x20_emb = SimpleNamespace(\n",
    "        backbone=cfg['emb_x20_backbone'], in_dim=dims[0], out_dim=dims[1],\n",
    "        scale=scale, dropout=cfg['dropout'], dw_conv=cfg['emb_x20_dw_conv'], ksize=cfg['emb_x20_ksize']\n",
    "    )\n",
    "    cfg_x5_emb = SimpleNamespace(\n",
    "        backbone=cfg['emb_x5_backbone'], in_dim=dims[0], out_dim=dims[1],\n",
    "        scale=1, dropout=cfg['dropout'], dw_conv=False, ksize=cfg['emb_x5_ksize']\n",
    "    )\n",
    "    cfg_tra_backbone = SimpleNamespace(\n",
    "        backbone=cfg['tra_backbone'], ksize=cfg['tra_ksize'], dw_conv=cfg['tra_dw_conv'],\n",
    "        d_model=dims[1], d_out=dims[2], nhead=cfg['tra_nhead'],\n",
    "        dropout=cfg['dropout'], num_layers=cfg['tra_num_layers'], epsilon=cfg['tra_epsilon']\n",
    "    )\n",
    "\n",
    "    model = WSIHierNet(dims, cfg_x20_emb, cfg_x5_emb, cfg_tra_backbone,\n",
    "                       dropout=cfg['dropout'], pool=cfg['pool'], join=cfg['join'], fusion=cfg['fusion'])\n",
    "\n",
    "    # === DeepSpeed 初始化 ===\n",
    "    ds_config_path = '/work/u6658716/TCGA-LUAD/DSCA/config/ds_config.json'\n",
    "    model_engine, _, _, _ = deepspeed.initialize(\n",
    "        model=model,\n",
    "        config_params=ds_config_path,\n",
    "        dist_init_required=False\n",
    "    )\n",
    "\n",
    "    # === 載入 best model（DeepSpeed 格式） ===\n",
    "    load_path = cfg['save_path']\n",
    "    print(f\"[INFO] Loading DeepSpeed checkpoint from {load_path}\")\n",
    "    success, _ = model_engine.load_checkpoint(load_path, tag=\"model-best\")\n",
    "    if not success:\n",
    "        raise RuntimeError(\"[ERROR] Failed to load DeepSpeed checkpoint\")\n",
    "\n",
    "    model_engine.eval()\n",
    "\n",
    "    # === 準備資料 ===\n",
    "    path_split = cfg['path_data_split'].format(cfg['seed_data_split'])\n",
    "    _, _, pids_test = read_datasplit_npz(path_split)\n",
    "    test_set = prepare_dataset(pids_test, cfg, cfg['magnification'])\n",
    "    test_loader = DataLoader(test_set, batch_size=cfg['batch_size'], num_workers=cfg['num_workers'], pin_memory=True)\n",
    "\n",
    "    # === 推論 ===\n",
    "    result = {'y': None, 'y_hat': None}\n",
    "    with torch.no_grad():\n",
    "        for fx, fx5, cx5, y in test_loader:\n",
    "            fx, fx5, cx5, y = fx.to(model_engine.local_rank), fx5.to(model_engine.local_rank), cx5.to(model_engine.local_rank), y.to(model_engine.local_rank)\n",
    "            y_hat = model_engine(fx, fx5, cx5)\n",
    "            result = collect_tensor(result, y.detach().cpu(), y_hat.detach().cpu())\n",
    "\n",
    "    y_true, y_pred = result['y'], result['y_hat']\n",
    "    c_index = evaluator(y_true, y_pred, metrics='cindex')\n",
    "    print(f\"[RESULT] Test C-index: {c_index:.4f}\")\n",
    "\n",
    "\n",
    "def get_config(config_path=\"config/config.yml\"):\n",
    "    with open(config_path, \"r\") as setting:\n",
    "        config = yaml.load(setting, Loader=yaml.FullLoader)\n",
    "    return config\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = get_config('/work/u6658716/TCGA-LUAD/DSCA/config/config_ms.yaml')\n",
    "    run_test(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
